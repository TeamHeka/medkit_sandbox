{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e117fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download dir: mtsamplesen.tar.gz untared in /Users/coulet/workspace/medkit/docs/adrien/data/\n",
      "Data dir: /Users/coulet/workspace/medkit/docs/adrien/data/mtsamplesen\n"
     ]
    }
   ],
   "source": [
    "## Download two clinical texts, with drug entites manually annotated\n",
    "import requests\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "#remote\n",
    "url_root = \"https://raw.githubusercontent.com/TeamHeka/data/main/\"\n",
    "archive=\"mtsamplesen.tar.gz\"\n",
    "url=url_root+archive\n",
    "\n",
    "#local\n",
    "local = os.getcwd()\n",
    "path=local+\"/data/\"\n",
    "if not os.path.isdir(path):\n",
    "    print(\"Create dir \"+path)\n",
    "    # directory does not exists\n",
    "    os.mkdir(path)\n",
    "\n",
    "response = requests.get(url, stream=True)\n",
    "file = tarfile.open(fileobj=response.raw, mode=\"r|gz\")\n",
    "file.extractall(path)\n",
    "\n",
    "mypath=path+\"mtsamplesen\"\n",
    "print(\"Data dir: \"+mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "425391c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read text doc as medkit documents\n",
    "from pathlib import Path\n",
    "from medkit.core.text import TextDocument\n",
    "\n",
    "docs = TextDocument.from_dir(path=Path(mypath), pattern='[A-Z0-9].txt', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b0de19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coulet/miniconda3/envs/medkit/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/coulet/miniconda3/envs/medkit/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "## Create and run a three-step doc pipeline that: \n",
    "# 1) split sentences in texts \n",
    "# 2) Recognize drug entities with NER1: a dictionnary-based approach named UMLSMatcher \n",
    "# 3) Recognize drug entities with NER2: a Transformer-based approach, see https://huggingface.co/samrawal/bert-large-uncased_med-ner\n",
    "from medkit.core import DocPipeline\n",
    "from medkit.core import Pipeline\n",
    "from medkit.core import PipelineStep\n",
    "from medkit.text.segmentation import SentenceTokenizer\n",
    "from medkit.text.ner import UMLSMatcher\n",
    "from medkit.text.ner.hf_entity_matcher import HFEntityMatcher\n",
    "\n",
    "# Def of the first step =============\n",
    "# By default, SentenceTokenizer will use a list of punctuation chars to detect sentences.\n",
    "sentence_tokenizer = SentenceTokenizer(\n",
    "    # Label of the segments created and returned by the operation\n",
    "    output_label=\"sentence\",\n",
    "    # Keep the punctuation character inside the sentence segments\n",
    "    keep_punct=True,\n",
    "    # Also split on newline chars, not just punctuation characters\n",
    "    split_on_newlines=True,\n",
    ")\n",
    "\n",
    "# Def of the second step =============\n",
    "# Codes of UMLS semantic groups to take into account\n",
    "umls_semgroups = [\"CHEM\"]  # chemical (the UMLS semantic group to take into account)\n",
    "umls_matcher = UMLSMatcher(\n",
    "    # Directory containing the UMLS files with terms and concepts\n",
    "    umls_dir=\"../data/UMLS/2023AB/META/\",\n",
    "    # Language to use (English)\n",
    "    language=\"ENG\",\n",
    "    # Where to store the temp term database of the matcher\n",
    "    cache_dir=\".umls_cache/\",\n",
    "    # Semantic groups to consider\n",
    "    semgroups=umls_semgroups,\n",
    "    # Don't be case-sensitive\n",
    "    lowercase=True,\n",
    "    # Convert special chars to ASCII before matching\n",
    "    normalize_unicode=True,\n",
    "    name=\"umls_matcher\"\n",
    ")\n",
    "\n",
    "# Def of the third step =============\n",
    "bert_matcher = HFEntityMatcher(model=\"samrawal/bert-large-uncased_med-ner\", name=\"bert_large\")# an alternate model: \"Clinical-AI-Apollo/Medical-NER\"\n",
    "\n",
    "\n",
    "pipeline3 = Pipeline(steps=[\n",
    "    PipelineStep(sentence_tokenizer, input_keys=[\"full_text\"], output_keys=[\"sentence\"]),\n",
    "    # deidentification step could come here\n",
    "    PipelineStep(umls_matcher, input_keys=[\"sentence\"], output_keys=[\"ner1_drug\"]), \n",
    "    PipelineStep(bert_matcher, input_keys=[\"sentence\"], output_keys=[\"ner2_drug\"])],\n",
    "                                          input_keys=[\"full_text\"],\n",
    "                                          output_keys=[\"sentence\", \"ner1_drug\", \"ner2_drug\"])\n",
    "\n",
    "doc_pipeline = DocPipeline(pipeline=pipeline3)\n",
    "doc_pipeline.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "163048d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load medkit documents with their manual annotations made with Brat (our ground truth)\n",
    "from medkit.io.brat import BratInputConverter\n",
    "\n",
    "# Define an Input Converter to load brat text and annot in medkit docs\n",
    "brat_converter = BratInputConverter()\n",
    "ref_docs = brat_converter.load(dir_path=mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93e97c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of docs: 2\n",
      "Doc a0b8880e-2e5f-11ef-ae9f-be2893d1605a: \n",
      "\t47 sentences,\n",
      "\t2 drugs found with NER1,\n",
      "\t6 drugs found with NER2,\n",
      "\t5 drugs manually annotated.\n",
      "Doc a0b89a2e-2e5f-11ef-ae9f-be2893d1605a: \n",
      "\t120 sentences,\n",
      "\t17 drugs found with NER1,\n",
      "\t19 drugs found with NER2,\n",
      "\t15 drugs manually annotated.\n"
     ]
    }
   ],
   "source": [
    "## Compute some stats\n",
    "print(f\"Nb of docs: {len(docs)}\")\n",
    "    \n",
    "i=0\n",
    "for doc in docs:\n",
    "    print (\"Doc \"+doc.uid+\": \")\n",
    "    # On annotations made by NER1 and NER2\n",
    "    sentence_nb = len(doc.anns.get(label=\"sentence\"))\n",
    "    print(f\"\\t{sentence_nb} sentences,\")\n",
    "    ner1_drug_nb = len(doc.anns.get(label=\"chemical\"))\n",
    "    print(f\"\\t{ner1_drug_nb} drugs found with NER1,\")  \n",
    "    ner2_drug_nb = len(doc.anns.get(label=\"m\"))\n",
    "    print(f\"\\t{ner2_drug_nb} drugs found with NER2,\")  \n",
    "    \n",
    "    # On the manual annotation (our ground truth)\n",
    "    gt_nb = len(ref_docs[i].anns.get(label=\"Drug\"))\n",
    "    print(f\"\\t{gt_nb} drugs manually annotated.\")  \n",
    "    i=+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "761abba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         NER1 (acc=0.99)             NER2 (acc=1.0)            \n",
      "Entities               P     R    F1              P     R    F1\n",
      "all                 0.89  0.85  0.87           0.76  0.95  0.84\n",
      "Drug                0.89  0.85  0.87           0.76  0.95  0.84\n"
     ]
    }
   ],
   "source": [
    "## Evaluate performance metrics of the NER1 and NER2 tools\n",
    "from medkit.text.metrics.ner import SeqEvalEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "def results_to_df(_results, _title):\n",
    "    results_list = list(_results.items())\n",
    "    arranged_results = {\"Entities\": ['P', 'R', 'F1'], \n",
    "                        \"all\": [round(results_list[i][1], 2) for i in [0, 1, 2]]}\n",
    "    accuracy = round(results_list[4][1], 2)\n",
    "\n",
    "    for i in range(5, len(results_list), 4):\n",
    "        key = results_list[i][0][:-10]\n",
    "        arranged_results[key] = [round(results_list[n][1], 2) for n in [i, i + 1, i + 2]]\n",
    "\n",
    "    df = pd.DataFrame(arranged_results, index=[f\"{_title} (acc={accuracy})\", '', '']).T\n",
    "    return df\n",
    "\n",
    "predicted_entities1=[]\n",
    "predicted_entities2=[]\n",
    "dfs = []\n",
    "\n",
    "for doc in docs:\n",
    "    predicted_entities1.append(doc.anns.get(label=\"chemical\"))\n",
    "    predicted_entities2.append(doc.anns.get(label=\"m\"))\n",
    "\n",
    "# Annotations of NER1 are labelled as 'chemical', NER2 as 'm', but as 'Drug' in the ground truth\n",
    "# The following dic enables remappings various labels of the same type of entites\n",
    "remapping= {\"chemical\": \"Drug\", \"m\": \"Drug\"}\n",
    "evaluator = SeqEvalEvaluator(return_metrics_by_label=True, average='weighted', labels_remapping=remapping) \n",
    "# eval of NER2\n",
    "results1 = evaluator.compute(ref_docs, predicted_entities1)\n",
    "dfs.append(results_to_df(_results=results1, _title=\"NER1\"))\n",
    "#print(results_to_df(_results=results1, _title=\"umls_matcher\"))\n",
    "# eval of NER2\n",
    "results2 = evaluator.compute(ref_docs, predicted_entities2)\n",
    "dfs.append(results_to_df(_results=results2, _title=\"NER2\"))\n",
    "\n",
    "print(pd.concat(dfs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd61fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write annotations of tool NER1 in the brat format\n",
    "from medkit.io.brat import BratOutputConverter\n",
    "\n",
    "# reload raw documents\n",
    "final_docs = TextDocument.from_dir(path=Path(mypath), pattern='[A-Z0-9].txt', encoding='utf-8')\n",
    "# simplified pipeline, with only the best NER tool (NER1)\n",
    "pipeline2 = Pipeline(steps=[\n",
    "    PipelineStep(sentence_tokenizer, input_keys=[\"full_text\"], output_keys=[\"sentence\"]),\n",
    "    # deidentification step could come here\n",
    "    PipelineStep(umls_matcher, input_keys=[\"sentence\"], output_keys=[\"ner1_drug\"])],\n",
    "                                          input_keys=[\"full_text\"],\n",
    "                                          output_keys=[\"ner1_drug\"])\n",
    "\n",
    "doc_pipeline2 = DocPipeline(pipeline=pipeline2)\n",
    "doc_pipeline2.run(final_docs)\n",
    "# Define Output Converter with default params,\n",
    "# transfer all annotations and attributes\n",
    "brat_output_converter = BratOutputConverter()\n",
    "\n",
    "out_path=\"/Users/coulet/workspace/brat/brat-1.3p1/data/mtsamplesen/ner1_out/\"\n",
    "\n",
    "# save the annotation with the best tool (considering F1 only) in `out_path`\n",
    "brat_output_converter.save(\n",
    "  final_docs,  dir_path=out_path, doc_names=[\"doc_1\", \"doc_2\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medkit",
   "language": "python",
   "name": "medkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
